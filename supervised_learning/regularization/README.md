# Holberton School Machine Learning Regularization Project

## Project Overview

This project focuses on implementing regularization techniques in machine learning using Python and TensorFlow. The main goal is to understand and apply L2 regularization, dropout, and early stopping to improve model performance and prevent overfitting.

## Files Description

- `0-l2_reg_cost.py`: Implements L2 regularization cost calculation.
- `1-l2_reg_gradient_descent.py`: Applies L2 regularization in gradient descent optimization.
- `2-l2_reg_cost.py`: TensorFlow function to calculate L2 regularization cost.
- `3-l2_reg_create_layer.py`: TensorFlow function to create a layer with L2 regularization.
- `4-dropout_forward_prop.py`: Implements forward propagation with dropout regularization.
- `5-dropout_gradient_descent.py`: Applies dropout regularization in gradient descent optimization.
- `6-dropout_create_layer.py`: TensorFlow function to create a layer with dropout regularization.
- `7-early_stopping.py`: Implements early stopping technique.
- `0-main.py` to `7-main.py`: Main files to test the corresponding Python scripts.

## Technologies

- Python 3.5+
- TensorFlow
- NumPy

## Usage

Each file can be executed independently to test its functionality. For example, to run `2-l2_reg_cost.py`, use the following command:

```bash
python3 2-main.py
```

## Authors

- **Chris Stamper** - [ZeroDayPoke](https://github.com/ZeroDayPoke)

## License

This project is licensed under the MIT License - see the LICENSE file for details.
